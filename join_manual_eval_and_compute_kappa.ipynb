{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"ForManualEval.xlsx\", engine=\"openpyxl\", index_col=\"Unnamed: 0\").drop(['Appropriateness'], axis=1)\n",
    "df2 = pd.read_excel(\"ForManualEval1.xlsx\", engine=\"openpyxl\", index_col=\"Unnamed: 0\").drop(['Appropriateness'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_orig_case</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>masked</th>\n",
       "      <th>predicted</th>\n",
       "      <th>new span</th>\n",
       "      <th>predicted_score</th>\n",
       "      <th>method</th>\n",
       "      <th>Humorousness</th>\n",
       "      <th>Grammaticality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163896</td>\n",
       "      <td>Is This Going To Make Me A Different Person? G...</td>\n",
       "      <td>AllTheNewsComponentsOne</td>\n",
       "      <td>Is this going to make me a different person? g...</td>\n",
       "      <td>Is this going to make me a different person ? ...</td>\n",
       "      <td>Is this going to make me a different person ? ...</td>\n",
       "      <td>monkey</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143206</td>\n",
       "      <td>Rio has turned Hope Solo into public enemy No. 1</td>\n",
       "      <td>AllTheNewsComponentsOne</td>\n",
       "      <td>Rio has turned hope solo into public enemy no. 1</td>\n",
       "      <td>Rio has turned hope solo into public enemy [MA...</td>\n",
       "      <td>Rio has turned hope solo into public enemy chi...</td>\n",
       "      <td>chihuahua</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1605</td>\n",
       "      <td>WHO says new drugs urgently needed to fight su...</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>Who says new drugs urgently needed to fight Su...</td>\n",
       "      <td>Who says new drugs urgently [MASK] to fight Su...</td>\n",
       "      <td>Who says new drugs urgently going to fight Sup...</td>\n",
       "      <td>going</td>\n",
       "      <td>0.951083</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69263</td>\n",
       "      <td>A top investor nails why Microsoft is getting ...</td>\n",
       "      <td>AllTheNewsComponentsOne</td>\n",
       "      <td>A top investor nails why Microsoft is getting ...</td>\n",
       "      <td>A top investor nails [MASK] Microsoft is getti...</td>\n",
       "      <td>A top investor nails microsoft Microsoft is ge...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>0.817679</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212657</td>\n",
       "      <td>As he moves campaign to battlegrounds, which D...</td>\n",
       "      <td>AllTheNewsKaggle</td>\n",
       "      <td>As he moves campaign to battlegrounds, which D...</td>\n",
       "      <td>As he moves campaign to battlegrounds , which ...</td>\n",
       "      <td>As he moves campaign to battlegrounds , which ...</td>\n",
       "      <td>duck</td>\n",
       "      <td>0.981560</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                    title_orig_case  \\\n",
       "0  163896  Is This Going To Make Me A Different Person? G...   \n",
       "1  143206   Rio has turned Hope Solo into public enemy No. 1   \n",
       "2    1605  WHO says new drugs urgently needed to fight su...   \n",
       "3   69263  A top investor nails why Microsoft is getting ...   \n",
       "4  212657  As he moves campaign to battlegrounds, which D...   \n",
       "\n",
       "                    source                                           headline  \\\n",
       "0  AllTheNewsComponentsOne  Is this going to make me a different person? g...   \n",
       "1  AllTheNewsComponentsOne   Rio has turned hope solo into public enemy no. 1   \n",
       "2                  Harvard  Who says new drugs urgently needed to fight Su...   \n",
       "3  AllTheNewsComponentsOne  A top investor nails why Microsoft is getting ...   \n",
       "4         AllTheNewsKaggle  As he moves campaign to battlegrounds, which D...   \n",
       "\n",
       "                                              masked  \\\n",
       "0  Is this going to make me a different person ? ...   \n",
       "1  Rio has turned hope solo into public enemy [MA...   \n",
       "2  Who says new drugs urgently [MASK] to fight Su...   \n",
       "3  A top investor nails [MASK] Microsoft is getti...   \n",
       "4  As he moves campaign to battlegrounds , which ...   \n",
       "\n",
       "                                           predicted   new span  \\\n",
       "0  Is this going to make me a different person ? ...     monkey   \n",
       "1  Rio has turned hope solo into public enemy chi...  chihuahua   \n",
       "2  Who says new drugs urgently going to fight Sup...      going   \n",
       "3  A top investor nails microsoft Microsoft is ge...  microsoft   \n",
       "4  As he moves campaign to battlegrounds , which ...       duck   \n",
       "\n",
       "   predicted_score        method  Humorousness  Grammaticality  \n",
       "0         0.999713  bert_humedit             0               2  \n",
       "1         0.999743  bert_humedit             1               2  \n",
       "2         0.951083  bert_humedit             0               2  \n",
       "3         0.817679  bert_humedit             0               1  \n",
       "4         0.981560  bert_humedit             3               3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_orig_case</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>masked</th>\n",
       "      <th>predicted</th>\n",
       "      <th>new span</th>\n",
       "      <th>predicted_score</th>\n",
       "      <th>method</th>\n",
       "      <th>Humorousness</th>\n",
       "      <th>Grammaticality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163896</td>\n",
       "      <td>Is This Going To Make Me A Different Person? G...</td>\n",
       "      <td>AllTheNewsComponentsOne</td>\n",
       "      <td>Is this going to make me a different person? g...</td>\n",
       "      <td>Is this going to make me a different person ? ...</td>\n",
       "      <td>Is this going to make me a different person ? ...</td>\n",
       "      <td>monkey</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143206</td>\n",
       "      <td>Rio has turned Hope Solo into public enemy No. 1</td>\n",
       "      <td>AllTheNewsComponentsOne</td>\n",
       "      <td>Rio has turned hope solo into public enemy no. 1</td>\n",
       "      <td>Rio has turned hope solo into public enemy [MA...</td>\n",
       "      <td>Rio has turned hope solo into public enemy chi...</td>\n",
       "      <td>chihuahua</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1605</td>\n",
       "      <td>WHO says new drugs urgently needed to fight su...</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>Who says new drugs urgently needed to fight Su...</td>\n",
       "      <td>Who says new drugs urgently [MASK] to fight Su...</td>\n",
       "      <td>Who says new drugs urgently going to fight Sup...</td>\n",
       "      <td>going</td>\n",
       "      <td>0.951083</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69263</td>\n",
       "      <td>A top investor nails why Microsoft is getting ...</td>\n",
       "      <td>AllTheNewsComponentsOne</td>\n",
       "      <td>A top investor nails why Microsoft is getting ...</td>\n",
       "      <td>A top investor nails [MASK] Microsoft is getti...</td>\n",
       "      <td>A top investor nails microsoft Microsoft is ge...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>0.817679</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212657</td>\n",
       "      <td>As he moves campaign to battlegrounds, which D...</td>\n",
       "      <td>AllTheNewsKaggle</td>\n",
       "      <td>As he moves campaign to battlegrounds, which D...</td>\n",
       "      <td>As he moves campaign to battlegrounds , which ...</td>\n",
       "      <td>As he moves campaign to battlegrounds , which ...</td>\n",
       "      <td>duck</td>\n",
       "      <td>0.981560</td>\n",
       "      <td>bert_humedit</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                    title_orig_case  \\\n",
       "0  163896  Is This Going To Make Me A Different Person? G...   \n",
       "1  143206   Rio has turned Hope Solo into public enemy No. 1   \n",
       "2    1605  WHO says new drugs urgently needed to fight su...   \n",
       "3   69263  A top investor nails why Microsoft is getting ...   \n",
       "4  212657  As he moves campaign to battlegrounds, which D...   \n",
       "\n",
       "                    source                                           headline  \\\n",
       "0  AllTheNewsComponentsOne  Is this going to make me a different person? g...   \n",
       "1  AllTheNewsComponentsOne   Rio has turned hope solo into public enemy no. 1   \n",
       "2                  Harvard  Who says new drugs urgently needed to fight Su...   \n",
       "3  AllTheNewsComponentsOne  A top investor nails why Microsoft is getting ...   \n",
       "4         AllTheNewsKaggle  As he moves campaign to battlegrounds, which D...   \n",
       "\n",
       "                                              masked  \\\n",
       "0  Is this going to make me a different person ? ...   \n",
       "1  Rio has turned hope solo into public enemy [MA...   \n",
       "2  Who says new drugs urgently [MASK] to fight Su...   \n",
       "3  A top investor nails [MASK] Microsoft is getti...   \n",
       "4  As he moves campaign to battlegrounds , which ...   \n",
       "\n",
       "                                           predicted   new span  \\\n",
       "0  Is this going to make me a different person ? ...     monkey   \n",
       "1  Rio has turned hope solo into public enemy chi...  chihuahua   \n",
       "2  Who says new drugs urgently going to fight Sup...      going   \n",
       "3  A top investor nails microsoft Microsoft is ge...  microsoft   \n",
       "4  As he moves campaign to battlegrounds , which ...       duck   \n",
       "\n",
       "   predicted_score        method  Humorousness  Grammaticality  \n",
       "0         0.999713  bert_humedit             2               3  \n",
       "1         0.999743  bert_humedit             1               3  \n",
       "2         0.951083  bert_humedit             0               3  \n",
       "3         0.817679  bert_humedit             0               0  \n",
       "4         0.981560  bert_humedit             2               3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.concat([df1,df2[['Humorousness','Grammaticality']].rename({'Humorousness':'Humorousness_b',\n",
    "                                                             'Grammaticality':'Grammaticality_b'},\n",
    "                                                             axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hum corr:  0.3583235600305203 Gram corr:  0.22007040433219197\n"
     ]
    }
   ],
   "source": [
    "print('Hum corr: ', df_merge['Humorousness'].corr(df_merge['Humorousness_b'], method='spearman'),\n",
    "'Gram corr: ', df_merge['Grammaticality'].corr(df_merge['Grammaticality_b'], method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hum corr:  0.32760024774116947 Gram corr:  0.1877074128002507\n"
     ]
    }
   ],
   "source": [
    "print('Hum corr: ', df_merge['Humorousness'].corr(df_merge['Humorousness_b'], method='kendall'),\n",
    "'Gram corr: ', df_merge['Grammaticality'].corr(df_merge['Grammaticality_b'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00404663938995562"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge[\"Humorousness\"].corr(df_merge[\"predicted_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1714272338006116"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge[\"Humorousness_b\"].corr(df_merge[\"predicted_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     126315.080000\n",
       "predicted_score             0.178145\n",
       "Humorousness                0.425000\n",
       "Grammaticality              2.245000\n",
       "Humorousness_b              0.725000\n",
       "Grammaticality_b            1.245000\n",
       "mean_humorousness           0.575000\n",
       "mean_grammaticality         1.745000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['mean_humorousness'] = df_merge.apply(lambda x: (x['Humorousness']+x['Humorousness_b'])/2,\n",
    "                                              axis=1)\n",
    "df_merge['mean_grammaticality'] = df_merge.apply(lambda x: (x['Grammaticality']+x['Grammaticality_b'])/2,\n",
    "                                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean       0.575000\n",
       "std        0.690477\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        3.000000\n",
       "Name: mean_humorousness, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['mean_humorousness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean       1.745000\n",
       "std        0.795701\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.750000\n",
       "75%        2.500000\n",
       "max        3.000000\n",
       "Name: mean_grammaticality, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['mean_grammaticality'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем по методам отдельно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bert_humedit', 'bert_jokes', 'colloc', 'jokecolloc'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_method(method):\n",
    "    subs = df_merge[df_merge['method']==method]\n",
    "    for feat in ('Humorousness','Humorousness_b','mean_humorousness'):\n",
    "        print(f\"{feat}:\")\n",
    "        print(subs[feat].describe())\n",
    "    print(f\"Humorousness kappa: {cohen_kappa_score(subs['Humorousness'], subs['Humorousness_b'])}\")\n",
    "    for feat in ('Grammaticality','Grammaticality_b','mean_grammaticality'):\n",
    "        print(f\"{feat}:\")\n",
    "        print(subs[feat].describe())\n",
    "    print(f\"Grammaticality kappa: {cohen_kappa_score(subs['Grammaticality'], subs['Grammaticality_b'])}\")\n",
    "    print(f\"Annot#1 corr with ColBert: {subs['Humorousness'].corr(subs['predicted_score'])}\")\n",
    "    print(f\"Annot#2 corr with ColBert: {subs['Humorousness_b'].corr(subs['predicted_score'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humorousness:\n",
      "count    50.000000\n",
      "mean      0.860000\n",
      "std       1.010355\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.500000\n",
      "75%       2.000000\n",
      "max       3.000000\n",
      "Name: Humorousness, dtype: float64\n",
      "Humorousness_b:\n",
      "count    50.000000\n",
      "mean      1.040000\n",
      "std       1.068281\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       1.000000\n",
      "75%       2.000000\n",
      "max       3.000000\n",
      "Name: Humorousness_b, dtype: float64\n",
      "mean_humorousness:\n",
      "count    50.000000\n",
      "mean      0.950000\n",
      "std       0.904919\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.750000\n",
      "75%       1.875000\n",
      "max       3.000000\n",
      "Name: mean_humorousness, dtype: float64\n",
      "Humorousness kappa: 0.23932124049151537\n",
      "Grammaticality:\n",
      "count    50.000000\n",
      "mean      2.600000\n",
      "std       0.728431\n",
      "min       0.000000\n",
      "25%       2.000000\n",
      "50%       3.000000\n",
      "75%       3.000000\n",
      "max       3.000000\n",
      "Name: Grammaticality, dtype: float64\n",
      "Grammaticality_b:\n",
      "count    50.00000\n",
      "mean      1.70000\n",
      "std       1.28174\n",
      "min       0.00000\n",
      "25%       0.00000\n",
      "50%       2.00000\n",
      "75%       3.00000\n",
      "max       3.00000\n",
      "Name: Grammaticality_b, dtype: float64\n",
      "mean_grammaticality:\n",
      "count    50.000000\n",
      "mean      2.150000\n",
      "std       0.764319\n",
      "min       0.500000\n",
      "25%       1.500000\n",
      "50%       2.500000\n",
      "75%       3.000000\n",
      "max       3.000000\n",
      "Name: mean_grammaticality, dtype: float64\n",
      "Grammaticality kappa: 0.07462686567164178\n",
      "Annot#1 corr with ColBert: -0.013082335416294178\n",
      "Annot#2 corr with ColBert: 0.2005207721651954\n"
     ]
    }
   ],
   "source": [
    "analyze_method(\"bert_humedit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humorousness:\n",
      "count    50.000000\n",
      "mean      0.220000\n",
      "std       0.581694\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max       3.000000\n",
      "Name: Humorousness, dtype: float64\n",
      "Humorousness_b:\n",
      "count    50.000000\n",
      "mean      0.660000\n",
      "std       0.871546\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       1.000000\n",
      "max       3.000000\n",
      "Name: Humorousness_b, dtype: float64\n",
      "mean_humorousness:\n",
      "count    50.00000\n",
      "mean      0.44000\n",
      "std       0.52138\n",
      "min       0.00000\n",
      "25%       0.00000\n",
      "50%       0.00000\n",
      "75%       1.00000\n",
      "max       1.50000\n",
      "Name: mean_humorousness, dtype: float64\n",
      "Humorousness kappa: 0.1329479768786127\n",
      "Grammaticality:\n",
      "count    50.000000\n",
      "mean      2.320000\n",
      "std       0.867556\n",
      "min       0.000000\n",
      "25%       2.000000\n",
      "50%       3.000000\n",
      "75%       3.000000\n",
      "max       3.000000\n",
      "Name: Grammaticality, dtype: float64\n",
      "Grammaticality_b:\n",
      "count    50.00000\n",
      "mean      1.28000\n",
      "std       1.03095\n",
      "min       0.00000\n",
      "25%       0.00000\n",
      "50%       1.00000\n",
      "75%       2.00000\n",
      "max       3.00000\n",
      "Name: Grammaticality_b, dtype: float64\n",
      "mean_grammaticality:\n",
      "count    50.000000\n",
      "mean      1.800000\n",
      "std       0.707107\n",
      "min       0.500000\n",
      "25%       1.125000\n",
      "50%       2.000000\n",
      "75%       2.500000\n",
      "max       3.000000\n",
      "Name: mean_grammaticality, dtype: float64\n",
      "Grammaticality kappa: -0.01990049751243772\n",
      "Annot#1 corr with ColBert: -0.042110530185036\n",
      "Annot#2 corr with ColBert: 0.18786390296524616\n"
     ]
    }
   ],
   "source": [
    "analyze_method('bert_jokes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humorousness:\n",
      "count    50.000000\n",
      "mean      0.280000\n",
      "std       0.607437\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max       2.000000\n",
      "Name: Humorousness, dtype: float64\n",
      "Humorousness_b:\n",
      "count    50.000000\n",
      "mean      0.580000\n",
      "std       0.758355\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       1.000000\n",
      "max       3.000000\n",
      "Name: Humorousness_b, dtype: float64\n",
      "mean_humorousness:\n",
      "count    50.000000\n",
      "mean      0.430000\n",
      "std       0.505177\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.500000\n",
      "75%       0.500000\n",
      "max       1.500000\n",
      "Name: mean_humorousness, dtype: float64\n",
      "Humorousness kappa: 0.05063291139240511\n",
      "Grammaticality:\n",
      "count    50.000000\n",
      "mean      2.000000\n",
      "std       1.010153\n",
      "min       0.000000\n",
      "25%       1.250000\n",
      "50%       2.000000\n",
      "75%       3.000000\n",
      "max       3.000000\n",
      "Name: Grammaticality, dtype: float64\n",
      "Grammaticality_b:\n",
      "count    50.000000\n",
      "mean      0.900000\n",
      "std       0.974156\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       1.000000\n",
      "75%       2.000000\n",
      "max       3.000000\n",
      "Name: Grammaticality_b, dtype: float64\n",
      "mean_grammaticality:\n",
      "count    50.000000\n",
      "mean      1.450000\n",
      "std       0.757614\n",
      "min       0.000000\n",
      "25%       1.000000\n",
      "50%       1.500000\n",
      "75%       2.000000\n",
      "max       2.500000\n",
      "Name: mean_grammaticality, dtype: float64\n",
      "Grammaticality kappa: -0.007556675062972307\n",
      "Annot#1 corr with ColBert: -0.06637673297040175\n",
      "Annot#2 corr with ColBert: 0.1466143867817351\n"
     ]
    }
   ],
   "source": [
    "analyze_method('colloc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humorousness:\n",
      "count    50.000000\n",
      "mean      0.340000\n",
      "std       0.688388\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max       3.000000\n",
      "Name: Humorousness, dtype: float64\n",
      "Humorousness_b:\n",
      "count    50.000000\n",
      "mean      0.620000\n",
      "std       0.779586\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       1.000000\n",
      "max       3.000000\n",
      "Name: Humorousness_b, dtype: float64\n",
      "mean_humorousness:\n",
      "count    50.000000\n",
      "mean      0.480000\n",
      "std       0.630516\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.500000\n",
      "75%       0.500000\n",
      "max       2.500000\n",
      "Name: mean_humorousness, dtype: float64\n",
      "Humorousness kappa: 0.24642049736247174\n",
      "Grammaticality:\n",
      "count    50.000000\n",
      "mean      2.060000\n",
      "std       1.057722\n",
      "min       0.000000\n",
      "25%       2.000000\n",
      "50%       2.000000\n",
      "75%       3.000000\n",
      "max       3.000000\n",
      "Name: Grammaticality, dtype: float64\n",
      "Grammaticality_b:\n",
      "count    50.000000\n",
      "mean      1.100000\n",
      "std       0.974156\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       1.000000\n",
      "75%       2.000000\n",
      "max       3.000000\n",
      "Name: Grammaticality_b, dtype: float64\n",
      "mean_grammaticality:\n",
      "count    50.000000\n",
      "mean      1.580000\n",
      "std       0.791279\n",
      "min       0.000000\n",
      "25%       1.000000\n",
      "50%       1.500000\n",
      "75%       2.000000\n",
      "max       3.000000\n",
      "Name: mean_grammaticality, dtype: float64\n",
      "Grammaticality kappa: 0.0220661985957874\n",
      "Annot#1 corr with ColBert: 0.026011371412769792\n",
      "Annot#2 corr with ColBert: 0.040826138046410804\n"
     ]
    }
   ],
   "source": [
    "analyze_method('jokecolloc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10828450041925756"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['mean_humorousness'].corr(df_merge['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00404663938995562"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['Humorousness'].corr(df_merge['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1714272338006116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['Humorousness_b'].corr(df_merge['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1900671977215077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(df_merge[\"Humorousness\"], df_merge[\"Humorousness_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04099584008129298"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(df_merge[\"Grammaticality\"], df_merge[\"Grammaticality_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merge[(df_merge['Humorousness']==df_merge['Humorousness_b'])&(df_merge['Grammaticality']==df_merge['Grammaticality_b'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_agreement = df_merge[(df_merge['Humorousness']==df_merge['Humorousness_b'])&(df_merge['Grammaticality']==df_merge['Grammaticality_b'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_agreement.to_csv(\"FullAgreement.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_humour_agreement = df_merge[(df_merge[\"Humorousness\"]==df_merge[\"Humorousness_b\"])&(df_merge[\"Grammaticality\"]!=df_merge[\"Grammaticality_b\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_humour_agreement.to_csv(\"OnlyHumAgreement.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_grammaticality_agreement = df_merge[(df_merge[\"Humorousness\"]!=df_merge[\"Humorousness_b\"])&(df_merge[\"Grammaticality\"]==df_merge[\"Grammaticality_b\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_grammaticality_agreement.to_csv(\"OnlyGramAgreement.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
